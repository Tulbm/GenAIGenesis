{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7045630,"sourceType":"datasetVersion","datasetId":4054274}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import HfApi, HfFolder\nimport os\n\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\n# Set the token for use in the huggingface_hub library\nHfFolder.save_token(hf_token)\n\nimport wandb\nfrom datasets import Dataset\n\n# Replace 'your-api-token' with your actual API token from wandb.ai\nwandb.login(key='88bc0f92c0138587605140040c6d0ef652bde63d')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-31T04:23:06.165583Z","iopub.execute_input":"2024-03-31T04:23:06.165922Z","iopub.status.idle":"2024-03-31T04:23:11.444004Z","shell.execute_reply.started":"2024-03-31T04:23:06.165895Z","shell.execute_reply":"2024-03-31T04:23:11.443127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/nlp-mental-health-conversations/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.445466Z","iopub.execute_input":"2024-03-31T04:23:11.445895Z","iopub.status.idle":"2024-03-31T04:23:11.560709Z","shell.execute_reply.started":"2024-03-31T04:23:11.44587Z","shell.execute_reply":"2024-03-31T04:23:11.559866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.56199Z","iopub.execute_input":"2024-03-31T04:23:11.562351Z","iopub.status.idle":"2024-03-31T04:23:11.572721Z","shell.execute_reply.started":"2024-03-31T04:23:11.562322Z","shell.execute_reply":"2024-03-31T04:23:11.571829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.574917Z","iopub.execute_input":"2024-03-31T04:23:11.575198Z","iopub.status.idle":"2024-03-31T04:23:11.595535Z","shell.execute_reply.started":"2024-03-31T04:23:11.575176Z","shell.execute_reply":"2024-03-31T04:23:11.594735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.59672Z","iopub.execute_input":"2024-03-31T04:23:11.597086Z","iopub.status.idle":"2024-03-31T04:23:11.603798Z","shell.execute_reply.started":"2024-03-31T04:23:11.597054Z","shell.execute_reply":"2024-03-31T04:23:11.602725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.604851Z","iopub.execute_input":"2024-03-31T04:23:11.605125Z","iopub.status.idle":"2024-03-31T04:23:11.618536Z","shell.execute_reply.started":"2024-03-31T04:23:11.605103Z","shell.execute_reply":"2024-03-31T04:23:11.617728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df.to_dict(orient='list')\n#data\ndata = Dataset.from_dict(data)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.619826Z","iopub.execute_input":"2024-03-31T04:23:11.620069Z","iopub.status.idle":"2024-03-31T04:23:11.665858Z","shell.execute_reply.started":"2024-03-31T04:23:11.620049Z","shell.execute_reply":"2024-03-31T04:23:11.665114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"google-t5/t5-base\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.666978Z","iopub.execute_input":"2024-03-31T04:23:11.667266Z","iopub.status.idle":"2024-03-31T04:23:19.796893Z","shell.execute_reply.started":"2024-03-31T04:23:11.667242Z","shell.execute_reply":"2024-03-31T04:23:19.795861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(examples):\n    # Tokenize the contexts. No need for return_tensors here.\n    model_inputs = tokenizer(examples[\"Context\"], max_length=512, truncation=True, padding=\"max_length\")\n\n    # Tokenize the responses. Note: We don't use return_tensors here to avoid the error.\n    labels = tokenizer(examples[\"Response\"], max_length=512, truncation=True, padding=\"max_length\")\n\n    # Here's a crucial part: setting -100 for the padding token ids in labels so they're not used in loss calculation\n    labels[\"input_ids\"] = [\n        [(label if label != tokenizer.pad_token_id else -100) for label in label_example] \n        for label_example in labels[\"input_ids\"]\n    ]\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:19.798104Z","iopub.execute_input":"2024-03-31T04:23:19.798602Z","iopub.status.idle":"2024-03-31T04:23:19.805546Z","shell.execute_reply.started":"2024-03-31T04:23:19.798576Z","shell.execute_reply":"2024-03-31T04:23:19.80443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_data = data.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:19.808829Z","iopub.execute_input":"2024-03-31T04:23:19.809121Z","iopub.status.idle":"2024-03-31T04:23:25.203836Z","shell.execute_reply.started":"2024-03-31T04:23:19.809089Z","shell.execute_reply":"2024-03-31T04:23:25.202921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install evaluate\n%pip install rouge_score\n%pip install bert-score  # If using BERTScore","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:25.205047Z","iopub.execute_input":"2024-03-31T04:23:25.205772Z","iopub.status.idle":"2024-03-31T04:24:07.353234Z","shell.execute_reply.started":"2024-03-31T04:23:25.205737Z","shell.execute_reply":"2024-03-31T04:24:07.351866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install -U nltk\n#from nltk.translate.meteor_score import meteor_score\nimport evaluate\n\n'''metrics = evaluate.combine(\n    [\n        evaluate.load(\"rouge\", use_aggregator=False),\n        #evaluate.load(\"meteor\"),  # Adding METEOR\n        evaluate.load(\"bertscore\", lang='en'),  # Adding BERTScore\n    ]\n)'''\nmetrics = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:07.355139Z","iopub.execute_input":"2024-03-31T04:24:07.355522Z","iopub.status.idle":"2024-03-31T04:24:23.386248Z","shell.execute_reply.started":"2024-03-31T04:24:07.355488Z","shell.execute_reply":"2024-03-31T04:24:23.38543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = metrics.compute(predictions=decoded_preds, references=decoded_labels)\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    # Adjust rounding to handle lists and non-numeric values\n    def safe_round(value, digits):\n        if isinstance(value, (int, float)):\n            return round(value, digits)\n        elif isinstance(value, list):\n            return [safe_round(v, digits) for v in value]\n        else:\n            return value\n\n    rounded_result = {k: safe_round(v, 4) for k, v in result.items()}\n\n    return rounded_result\n","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:23.387393Z","iopub.execute_input":"2024-03-31T04:24:23.388281Z","iopub.status.idle":"2024-03-31T04:24:23.397052Z","shell.execute_reply.started":"2024-03-31T04:24:23.388253Z","shell.execute_reply":"2024-03-31T04:24:23.396138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:23.398275Z","iopub.execute_input":"2024-03-31T04:24:23.398585Z","iopub.status.idle":"2024-03-31T04:24:23.410653Z","shell.execute_reply.started":"2024-03-31T04:24:23.39853Z","shell.execute_reply":"2024-03-31T04:24:23.409744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\ncheckpoint = \"google-t5/t5-base\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:23.411817Z","iopub.execute_input":"2024-03-31T04:24:23.412103Z","iopub.status.idle":"2024-03-31T04:24:29.171849Z","shell.execute_reply.started":"2024-03-31T04:24:23.412079Z","shell.execute_reply":"2024-03-31T04:24:29.170902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_data = tokenized_data.train_test_split(test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:29.17312Z","iopub.execute_input":"2024-03-31T04:24:29.173438Z","iopub.status.idle":"2024-03-31T04:24:29.188016Z","shell.execute_reply.started":"2024-03-31T04:24:29.173414Z","shell.execute_reply":"2024-03-31T04:24:29.187047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_data","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:29.18916Z","iopub.execute_input":"2024-03-31T04:24:29.189488Z","iopub.status.idle":"2024-03-31T04:24:29.195819Z","shell.execute_reply.started":"2024-03-31T04:24:29.189456Z","shell.execute_reply":"2024-03-31T04:24:29.194956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tokenized_data[\"train\"].features)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:29.196901Z","iopub.execute_input":"2024-03-31T04:24:29.197221Z","iopub.status.idle":"2024-03-31T04:24:29.206786Z","shell.execute_reply.started":"2024-03-31T04:24:29.197191Z","shell.execute_reply":"2024-03-31T04:24:29.205699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"Mental_health_response\",\n    evaluation_strategy=\"epoch\",  # Change from \"epoch\" to \"steps\"\n    learning_rate=2e-3,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    weight_decay=0.1,\n    save_total_limit=3,\n    num_train_epochs=5,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=True,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_data[\"train\"],\n    eval_dataset=tokenized_data[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T05:13:08.2145Z","iopub.execute_input":"2024-03-31T05:13:08.215289Z","iopub.status.idle":"2024-03-31T06:14:40.214775Z","shell.execute_reply.started":"2024-03-31T05:13:08.215255Z","shell.execute_reply":"2024-03-31T06:14:40.213739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T06:14:40.216363Z","iopub.execute_input":"2024-03-31T06:14:40.216654Z","iopub.status.idle":"2024-03-31T06:15:09.769569Z","shell.execute_reply.started":"2024-03-31T06:14:40.216628Z","shell.execute_reply":"2024-03-31T06:15:09.768565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}