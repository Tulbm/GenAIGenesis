{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7045630,"sourceType":"datasetVersion","datasetId":4054274}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import HfApi, HfFolder\nimport os\n\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\n# Set the token for use in the huggingface_hub library\nHfFolder.save_token(hf_token)\n\nimport wandb\nfrom datasets import Dataset\n\n# Replace 'your-api-token' with your actual API token from wandb.ai\nwandb.login(key='88bc0f92c0138587605140040c6d0ef652bde63d')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-31T04:23:06.165583Z","iopub.execute_input":"2024-03-31T04:23:06.165922Z","iopub.status.idle":"2024-03-31T04:23:11.444004Z","shell.execute_reply.started":"2024-03-31T04:23:06.165895Z","shell.execute_reply":"2024-03-31T04:23:11.443127Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/nlp-mental-health-conversations/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.445466Z","iopub.execute_input":"2024-03-31T04:23:11.445895Z","iopub.status.idle":"2024-03-31T04:23:11.560709Z","shell.execute_reply.started":"2024-03-31T04:23:11.445870Z","shell.execute_reply":"2024-03-31T04:23:11.559866Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.561990Z","iopub.execute_input":"2024-03-31T04:23:11.562351Z","iopub.status.idle":"2024-03-31T04:23:11.572721Z","shell.execute_reply.started":"2024-03-31T04:23:11.562322Z","shell.execute_reply":"2024-03-31T04:23:11.571829Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.574917Z","iopub.execute_input":"2024-03-31T04:23:11.575198Z","iopub.status.idle":"2024-03-31T04:23:11.595535Z","shell.execute_reply.started":"2024-03-31T04:23:11.575176Z","shell.execute_reply":"2024-03-31T04:23:11.594735Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                Context  \\\n0     I'm going through some things with my feelings...   \n1     I'm going through some things with my feelings...   \n2     I'm going through some things with my feelings...   \n3     I'm going through some things with my feelings...   \n4     I'm going through some things with my feelings...   \n...                                                 ...   \n3507  My grandson's step-mother sends him to school ...   \n3508  My boyfriend is in recovery from drug addictio...   \n3509  The birth mother attempted suicide several tim...   \n3510  I think adult life is making him depressed and...   \n3511  I just took a job that requires me to travel f...   \n\n                                               Response  \n0     If everyone thinks you're worthless, then mayb...  \n1     Hello, and thank you for your question and see...  \n2     First thing I'd suggest is getting the sleep y...  \n3     Therapy is essential for those that are feelin...  \n4     I first want to let you know that you are not ...  \n...                                                 ...  \n3507  Absolutely not! It is never in a child's best ...  \n3508  I'm sorry you have tension between you and you...  \n3509  The true answer is, \"no one can really say wit...  \n3510  How do you help yourself to believe you requir...  \n3511                           hmm this is a tough one!  \n\n[3508 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Context</th>\n      <th>Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I'm going through some things with my feelings...</td>\n      <td>If everyone thinks you're worthless, then mayb...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I'm going through some things with my feelings...</td>\n      <td>Hello, and thank you for your question and see...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I'm going through some things with my feelings...</td>\n      <td>First thing I'd suggest is getting the sleep y...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I'm going through some things with my feelings...</td>\n      <td>Therapy is essential for those that are feelin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I'm going through some things with my feelings...</td>\n      <td>I first want to let you know that you are not ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3507</th>\n      <td>My grandson's step-mother sends him to school ...</td>\n      <td>Absolutely not! It is never in a child's best ...</td>\n    </tr>\n    <tr>\n      <th>3508</th>\n      <td>My boyfriend is in recovery from drug addictio...</td>\n      <td>I'm sorry you have tension between you and you...</td>\n    </tr>\n    <tr>\n      <th>3509</th>\n      <td>The birth mother attempted suicide several tim...</td>\n      <td>The true answer is, \"no one can really say wit...</td>\n    </tr>\n    <tr>\n      <th>3510</th>\n      <td>I think adult life is making him depressed and...</td>\n      <td>How do you help yourself to believe you requir...</td>\n    </tr>\n    <tr>\n      <th>3511</th>\n      <td>I just took a job that requires me to travel f...</td>\n      <td>hmm this is a tough one!</td>\n    </tr>\n  </tbody>\n</table>\n<p>3508 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.596720Z","iopub.execute_input":"2024-03-31T04:23:11.597086Z","iopub.status.idle":"2024-03-31T04:23:11.603798Z","shell.execute_reply.started":"2024-03-31T04:23:11.597054Z","shell.execute_reply":"2024-03-31T04:23:11.602725Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.604851Z","iopub.execute_input":"2024-03-31T04:23:11.605125Z","iopub.status.idle":"2024-03-31T04:23:11.618536Z","shell.execute_reply.started":"2024-03-31T04:23:11.605103Z","shell.execute_reply":"2024-03-31T04:23:11.617728Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                Context  \\\n0     I have no friends, no hobbies, and no interest...   \n1     I had a dispute with my therapist regarding an...   \n2     I'm in my early 20s, and I've been seeing my b...   \n3     I have been married for 11 years. Within the p...   \n4     I've been suppressing it for quite some time, ...   \n...                                                 ...   \n3503  In middle school and high school, my friends a...   \n3504  My ex-wife married and used me to have a child...   \n3505  I’ve been on 0.5 mg of Xanax twice a day for t...   \n3506  I've always thought that there wasn't much goo...   \n3507  He wants to wear makeup and heels. He even tuc...   \n\n                                               Response  \n0     Hello, and thank you for your question. It cer...  \n1     My recommendation would be to try to talk to y...  \n2     My first thought was that I wondered what chan...  \n3     I'm sorry for how you're feeling in your marri...  \n4     Human attractions can be tricky things, and in...  \n...                                                 ...  \n3503  Use this time to explore who you are...imagine...  \n3504  The thing that confuses a child the most is fo...  \n3505  Staying on the lower dose may give you more ro...  \n3506  Congrats on having a happiness problem.Go slow...  \n3507  It sounds like you may be asking two different...  \n\n[3508 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Context</th>\n      <th>Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I have no friends, no hobbies, and no interest...</td>\n      <td>Hello, and thank you for your question. It cer...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I had a dispute with my therapist regarding an...</td>\n      <td>My recommendation would be to try to talk to y...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I'm in my early 20s, and I've been seeing my b...</td>\n      <td>My first thought was that I wondered what chan...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I have been married for 11 years. Within the p...</td>\n      <td>I'm sorry for how you're feeling in your marri...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I've been suppressing it for quite some time, ...</td>\n      <td>Human attractions can be tricky things, and in...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3503</th>\n      <td>In middle school and high school, my friends a...</td>\n      <td>Use this time to explore who you are...imagine...</td>\n    </tr>\n    <tr>\n      <th>3504</th>\n      <td>My ex-wife married and used me to have a child...</td>\n      <td>The thing that confuses a child the most is fo...</td>\n    </tr>\n    <tr>\n      <th>3505</th>\n      <td>I’ve been on 0.5 mg of Xanax twice a day for t...</td>\n      <td>Staying on the lower dose may give you more ro...</td>\n    </tr>\n    <tr>\n      <th>3506</th>\n      <td>I've always thought that there wasn't much goo...</td>\n      <td>Congrats on having a happiness problem.Go slow...</td>\n    </tr>\n    <tr>\n      <th>3507</th>\n      <td>He wants to wear makeup and heels. He even tuc...</td>\n      <td>It sounds like you may be asking two different...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3508 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = df.to_dict(orient='list')\n#data\ndata = Dataset.from_dict(data)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.619826Z","iopub.execute_input":"2024-03-31T04:23:11.620069Z","iopub.status.idle":"2024-03-31T04:23:11.665858Z","shell.execute_reply.started":"2024-03-31T04:23:11.620049Z","shell.execute_reply":"2024-03-31T04:23:11.665114Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"google-t5/t5-base\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:11.666978Z","iopub.execute_input":"2024-03-31T04:23:11.667266Z","iopub.status.idle":"2024-03-31T04:23:19.796893Z","shell.execute_reply.started":"2024-03-31T04:23:11.667242Z","shell.execute_reply":"2024-03-31T04:23:19.795861Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b22ed1cd4a4844ac5b8ce8762bd16b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd7686fc775d440086c975f8549dd915"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c127739c91a433dbe6192a20d31cab0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:171: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on google-t5/t5-base automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    # Tokenize the contexts. No need for return_tensors here.\n    model_inputs = tokenizer(examples[\"Context\"], max_length=512, truncation=True, padding=\"max_length\")\n\n    # Tokenize the responses. Note: We don't use return_tensors here to avoid the error.\n    labels = tokenizer(examples[\"Response\"], max_length=512, truncation=True, padding=\"max_length\")\n\n    # Here's a crucial part: setting -100 for the padding token ids in labels so they're not used in loss calculation\n    labels[\"input_ids\"] = [\n        [(label if label != tokenizer.pad_token_id else -100) for label in label_example] \n        for label_example in labels[\"input_ids\"]\n    ]\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:19.798104Z","iopub.execute_input":"2024-03-31T04:23:19.798602Z","iopub.status.idle":"2024-03-31T04:23:19.805546Z","shell.execute_reply.started":"2024-03-31T04:23:19.798576Z","shell.execute_reply":"2024-03-31T04:23:19.804430Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tokenized_data = data.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:19.808829Z","iopub.execute_input":"2024-03-31T04:23:19.809121Z","iopub.status.idle":"2024-03-31T04:23:25.203836Z","shell.execute_reply.started":"2024-03-31T04:23:19.809089Z","shell.execute_reply":"2024-03-31T04:23:25.202921Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"066fe5671a674f97883c5d01a7164cd0"}},"metadata":{}}]},{"cell_type":"code","source":"%pip install evaluate\n%pip install rouge_score\n%pip install bert-score  # If using BERTScore","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:23:25.205047Z","iopub.execute_input":"2024-03-31T04:23:25.205772Z","iopub.status.idle":"2024-03-31T04:24:07.353234Z","shell.execute_reply.started":"2024-03-31T04:23:25.205737Z","shell.execute_reply":"2024-03-31T04:24:07.351866Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.21.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m995.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=8e97b518f05aa441f673a4f4be1eb11016d6cdcff92c57046152164148a2bd8e\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.1.2)\nRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.1.4)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.38.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.31.0)\nRequirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.66.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert-score) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert-score) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2024.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.21.4)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (2024.2.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m862.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m--:--\u001b[0m\n\u001b[?25hInstalling collected packages: bert-score\nSuccessfully installed bert-score-0.3.13\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"#!pip install -U nltk\n#from nltk.translate.meteor_score import meteor_score\nimport evaluate\n\n'''metrics = evaluate.combine(\n    [\n        evaluate.load(\"rouge\", use_aggregator=False),\n        #evaluate.load(\"meteor\"),  # Adding METEOR\n        evaluate.load(\"bertscore\", lang='en'),  # Adding BERTScore\n    ]\n)'''\nmetrics = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:07.355139Z","iopub.execute_input":"2024-03-31T04:24:07.355522Z","iopub.status.idle":"2024-03-31T04:24:23.386248Z","shell.execute_reply.started":"2024-03-31T04:24:07.355488Z","shell.execute_reply":"2024-03-31T04:24:23.385430Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2024-03-31 04:24:09.428377: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-31 04:24:09.428502: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-31 04:24:09.590910: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b5219cc34164755bac5e9ba27d36ce0"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = metrics.compute(predictions=decoded_preds, references=decoded_labels)\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    # Adjust rounding to handle lists and non-numeric values\n    def safe_round(value, digits):\n        if isinstance(value, (int, float)):\n            return round(value, digits)\n        elif isinstance(value, list):\n            return [safe_round(v, digits) for v in value]\n        else:\n            return value\n\n    rounded_result = {k: safe_round(v, 4) for k, v in result.items()}\n\n    return rounded_result\n","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:23.387393Z","iopub.execute_input":"2024-03-31T04:24:23.388281Z","iopub.status.idle":"2024-03-31T04:24:23.397052Z","shell.execute_reply.started":"2024-03-31T04:24:23.388253Z","shell.execute_reply":"2024-03-31T04:24:23.396138Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:23.398275Z","iopub.execute_input":"2024-03-31T04:24:23.398585Z","iopub.status.idle":"2024-03-31T04:24:23.410653Z","shell.execute_reply.started":"2024-03-31T04:24:23.398530Z","shell.execute_reply":"2024-03-31T04:24:23.409744Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\ncheckpoint = \"google-t5/t5-base\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:23.411817Z","iopub.execute_input":"2024-03-31T04:24:23.412103Z","iopub.status.idle":"2024-03-31T04:24:29.171849Z","shell.execute_reply.started":"2024-03-31T04:24:23.412079Z","shell.execute_reply":"2024-03-31T04:24:29.170902Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f06f09e64aac430dbfce8cb3fe98da44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b331976cddc4b5bbca05043477948d4"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_data = tokenized_data.train_test_split(test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:29.173120Z","iopub.execute_input":"2024-03-31T04:24:29.173438Z","iopub.status.idle":"2024-03-31T04:24:29.188016Z","shell.execute_reply.started":"2024-03-31T04:24:29.173414Z","shell.execute_reply":"2024-03-31T04:24:29.187047Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tokenized_data","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:29.189160Z","iopub.execute_input":"2024-03-31T04:24:29.189488Z","iopub.status.idle":"2024-03-31T04:24:29.195819Z","shell.execute_reply.started":"2024-03-31T04:24:29.189456Z","shell.execute_reply":"2024-03-31T04:24:29.194956Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Context', 'Response', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 2631\n    })\n    test: Dataset({\n        features: ['Context', 'Response', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 877\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(tokenized_data[\"train\"].features)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T04:24:29.196901Z","iopub.execute_input":"2024-03-31T04:24:29.197221Z","iopub.status.idle":"2024-03-31T04:24:29.206786Z","shell.execute_reply.started":"2024-03-31T04:24:29.197191Z","shell.execute_reply":"2024-03-31T04:24:29.205699Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"{'Context': Value(dtype='string', id=None), 'Response': Value(dtype='string', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"Mental_health_response\",\n    evaluation_strategy=\"epoch\",  # Change from \"epoch\" to \"steps\"\n    learning_rate=2e-3,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    weight_decay=0.1,\n    save_total_limit=3,\n    num_train_epochs=5,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=True,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_data[\"train\"],\n    eval_dataset=tokenized_data[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T05:13:08.214500Z","iopub.execute_input":"2024-03-31T05:13:08.215289Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='206' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 206/3290 02:49 < 42:38, 1.21 it/s, Epoch 0.31/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}